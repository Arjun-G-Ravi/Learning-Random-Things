{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/arjun/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so\n",
      "/home/arjun/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "ERROR: /home/arjun/NewPytorchEnv/bin/python3.10: undefined symbol: cudaRuntimeGetVersion\n",
      "CUDA SETUP: libcudart.so path is None\n",
      "CUDA SETUP: Is seems that your cuda installation is not in your path. See https://github.com/TimDettmers/bitsandbytes/issues/85 for more information.\n",
      "CUDA SETUP: CUDA version lower than 11 are currently not supported for LLM.int8(). You will be only to use 8-bit optimizers and quantization routines!!\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 00\n",
      "CUDA SETUP: Loading binary /home/arjun/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjun/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "/home/arjun/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('0'), PosixPath('1')}\n",
      "  warn(msg)\n",
      "/home/arjun/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('local/PC'), PosixPath('@/tmp/.ICE-unix/1578,unix/PC')}\n",
      "  warn(msg)\n",
      "/home/arjun/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/home/arjun/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/etc/xdg/xdg-ubuntu')}\n",
      "  warn(msg)\n",
      "/home/arjun/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/var/lib/flatpak/exports/share')}\n",
      "  warn(msg)\n",
      "/home/arjun/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/home/arjun/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib64')}\n",
      "  warn(msg)\n",
      "/home/arjun/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: No libcudart.so found! Install CUDA or the cudatoolkit package (anaconda)!\n",
      "  warn(msg)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "/home/arjun/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cget_col_row_stats",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[0;32m----> 2\u001b[0m pipe \u001b[39m=\u001b[39m pipeline(model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgpt2\u001b[39;49m\u001b[39m'\u001b[39;49m, model_kwargs\u001b[39m=\u001b[39;49m {\u001b[39m\"\u001b[39;49m\u001b[39mdevice_map\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mload_in_8bit\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m}, max_new_tokens\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "File \u001b[0;32m~/NewPytorchEnv/lib/python3.10/site-packages/transformers/pipelines/__init__.py:776\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    775\u001b[0m     model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m--> 776\u001b[0m     framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[1;32m    777\u001b[0m         model,\n\u001b[1;32m    778\u001b[0m         model_classes\u001b[39m=\u001b[39;49mmodel_classes,\n\u001b[1;32m    779\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    780\u001b[0m         framework\u001b[39m=\u001b[39;49mframework,\n\u001b[1;32m    781\u001b[0m         task\u001b[39m=\u001b[39;49mtask,\n\u001b[1;32m    782\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs,\n\u001b[1;32m    783\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m    784\u001b[0m     )\n\u001b[1;32m    786\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    787\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m~/NewPytorchEnv/lib/python3.10/site-packages/transformers/pipelines/base.py:269\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    264\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    265\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTrying to load the model with Tensorflow.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m     )\n\u001b[1;32m    268\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     model \u001b[39m=\u001b[39m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39meval\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    271\u001b[0m         model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/NewPytorchEnv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:493\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    492\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    494\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    495\u001b[0m     )\n\u001b[1;32m    496\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    497\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m )\n",
      "File \u001b[0;32m~/NewPytorchEnv/lib/python3.10/site-packages/transformers/modeling_utils.py:2907\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2897\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2898\u001b[0m         torch\u001b[39m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   2900\u001b[0m     (\n\u001b[1;32m   2901\u001b[0m         model,\n\u001b[1;32m   2902\u001b[0m         missing_keys,\n\u001b[1;32m   2903\u001b[0m         unexpected_keys,\n\u001b[1;32m   2904\u001b[0m         mismatched_keys,\n\u001b[1;32m   2905\u001b[0m         offload_index,\n\u001b[1;32m   2906\u001b[0m         error_msgs,\n\u001b[0;32m-> 2907\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_pretrained_model(\n\u001b[1;32m   2908\u001b[0m         model,\n\u001b[1;32m   2909\u001b[0m         state_dict,\n\u001b[1;32m   2910\u001b[0m         loaded_state_dict_keys,  \u001b[39m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   2911\u001b[0m         resolved_archive_file,\n\u001b[1;32m   2912\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   2913\u001b[0m         ignore_mismatched_sizes\u001b[39m=\u001b[39;49mignore_mismatched_sizes,\n\u001b[1;32m   2914\u001b[0m         sharded_metadata\u001b[39m=\u001b[39;49msharded_metadata,\n\u001b[1;32m   2915\u001b[0m         _fast_init\u001b[39m=\u001b[39;49m_fast_init,\n\u001b[1;32m   2916\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49mlow_cpu_mem_usage,\n\u001b[1;32m   2917\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m   2918\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m   2919\u001b[0m         offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[1;32m   2920\u001b[0m         dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[1;32m   2921\u001b[0m         is_quantized\u001b[39m=\u001b[39;49m(load_in_8bit \u001b[39mor\u001b[39;49;00m load_in_4bit),\n\u001b[1;32m   2922\u001b[0m         keep_in_fp32_modules\u001b[39m=\u001b[39;49mkeep_in_fp32_modules,\n\u001b[1;32m   2923\u001b[0m     )\n\u001b[1;32m   2925\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_4bit \u001b[39m=\u001b[39m load_in_4bit\n\u001b[1;32m   2926\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_8bit \u001b[39m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m~/NewPytorchEnv/lib/python3.10/site-packages/transformers/modeling_utils.py:3268\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3258\u001b[0m mismatched_keys \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m   3259\u001b[0m     state_dict,\n\u001b[1;32m   3260\u001b[0m     model_state_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3264\u001b[0m     ignore_mismatched_sizes,\n\u001b[1;32m   3265\u001b[0m )\n\u001b[1;32m   3267\u001b[0m \u001b[39mif\u001b[39;00m low_cpu_mem_usage:\n\u001b[0;32m-> 3268\u001b[0m     new_error_msgs, offload_index, state_dict_index \u001b[39m=\u001b[39m _load_state_dict_into_meta_model(\n\u001b[1;32m   3269\u001b[0m         model_to_load,\n\u001b[1;32m   3270\u001b[0m         state_dict,\n\u001b[1;32m   3271\u001b[0m         loaded_keys,\n\u001b[1;32m   3272\u001b[0m         start_prefix,\n\u001b[1;32m   3273\u001b[0m         expected_keys,\n\u001b[1;32m   3274\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m   3275\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m   3276\u001b[0m         offload_index\u001b[39m=\u001b[39;49moffload_index,\n\u001b[1;32m   3277\u001b[0m         state_dict_folder\u001b[39m=\u001b[39;49mstate_dict_folder,\n\u001b[1;32m   3278\u001b[0m         state_dict_index\u001b[39m=\u001b[39;49mstate_dict_index,\n\u001b[1;32m   3279\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   3280\u001b[0m         is_quantized\u001b[39m=\u001b[39;49mis_quantized,\n\u001b[1;32m   3281\u001b[0m         is_safetensors\u001b[39m=\u001b[39;49mis_safetensors,\n\u001b[1;32m   3282\u001b[0m         keep_in_fp32_modules\u001b[39m=\u001b[39;49mkeep_in_fp32_modules,\n\u001b[1;32m   3283\u001b[0m     )\n\u001b[1;32m   3284\u001b[0m     error_msgs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m new_error_msgs\n\u001b[1;32m   3285\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/NewPytorchEnv/lib/python3.10/site-packages/transformers/modeling_utils.py:729\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, is_quantized, is_safetensors, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m    726\u001b[0m             fp16_statistics \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    728\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mSCB\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m param_name:\n\u001b[0;32m--> 729\u001b[0m             set_module_quantized_tensor_to_device(\n\u001b[1;32m    730\u001b[0m                 model, param_name, param_device, value\u001b[39m=\u001b[39;49mparam, fp16_statistics\u001b[39m=\u001b[39;49mfp16_statistics\n\u001b[1;32m    731\u001b[0m             )\n\u001b[1;32m    733\u001b[0m \u001b[39mreturn\u001b[39;00m error_msgs, offload_index, state_dict_index\n",
      "File \u001b[0;32m~/NewPytorchEnv/lib/python3.10/site-packages/transformers/utils/bitsandbytes.py:97\u001b[0m, in \u001b[0;36mset_module_quantized_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, fp16_statistics)\u001b[0m\n\u001b[1;32m     95\u001b[0m kwargs \u001b[39m=\u001b[39m old_value\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m is_8bit:\n\u001b[0;32m---> 97\u001b[0m     new_value \u001b[39m=\u001b[39m bnb\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mInt8Params(new_value, requires_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     98\u001b[0m \u001b[39melif\u001b[39;00m is_4bit:\n\u001b[1;32m     99\u001b[0m     new_value \u001b[39m=\u001b[39m bnb\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mParams4bit(new_value, requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:294\u001b[0m, in \u001b[0;36mInt8Params.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m device, dtype, non_blocking, convert_to_format \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39m_parse_to(\n\u001b[1;32m    286\u001b[0m     \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    287\u001b[0m )\n\u001b[1;32m    289\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    290\u001b[0m     device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     \u001b[39mand\u001b[39;00m device\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m ):\n\u001b[0;32m--> 294\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcuda(device)\n\u001b[1;32m    295\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     new_param \u001b[39m=\u001b[39m Int8Params(\n\u001b[1;32m    297\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mto(\n\u001b[1;32m    298\u001b[0m             device\u001b[39m=\u001b[39mdevice, dtype\u001b[39m=\u001b[39mdtype, non_blocking\u001b[39m=\u001b[39mnon_blocking\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    301\u001b[0m         has_fp16_weights\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_fp16_weights,\n\u001b[1;32m    302\u001b[0m     )\n",
      "File \u001b[0;32m~/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:258\u001b[0m, in \u001b[0;36mInt8Params.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[39m# we store the 8-bit rows-major weight\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[39m# we convert this weight to the turning/ampere weight during the first inference pass\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     B \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mhalf()\u001b[39m.\u001b[39mcuda(device)\n\u001b[0;32m--> 258\u001b[0m     CB, CBt, SCB, SCBt, coo_tensorB \u001b[39m=\u001b[39m bnb\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mdouble_quant(B)\n\u001b[1;32m    259\u001b[0m     \u001b[39mdel\u001b[39;00m CBt\n\u001b[1;32m    260\u001b[0m     \u001b[39mdel\u001b[39;00m SCBt\n",
      "File \u001b[0;32m~/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/functional.py:1987\u001b[0m, in \u001b[0;36mdouble_quant\u001b[0;34m(A, col_stats, row_stats, out_col, out_row, threshold)\u001b[0m\n\u001b[1;32m   1984\u001b[0m     rows \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1986\u001b[0m \u001b[39mif\u001b[39;00m row_stats \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m col_stats \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1987\u001b[0m     row_stats, col_stats, nnz_row_ptr \u001b[39m=\u001b[39m get_colrow_absmax(\n\u001b[1;32m   1988\u001b[0m         A, threshold\u001b[39m=\u001b[39;49mthreshold\n\u001b[1;32m   1989\u001b[0m     )\n\u001b[1;32m   1991\u001b[0m \u001b[39mif\u001b[39;00m out_col \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1992\u001b[0m     out_col \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(A\u001b[39m.\u001b[39mshape, device\u001b[39m=\u001b[39mdevice, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint8)\n",
      "File \u001b[0;32m~/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/functional.py:1876\u001b[0m, in \u001b[0;36mget_colrow_absmax\u001b[0;34m(A, row_stats, col_stats, nnz_block_ptr, threshold)\u001b[0m\n\u001b[1;32m   1874\u001b[0m prev_device \u001b[39m=\u001b[39m pre_call(A\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   1875\u001b[0m is_on_gpu([A, row_stats, col_stats, nnz_block_ptr])\n\u001b[0;32m-> 1876\u001b[0m lib\u001b[39m.\u001b[39;49mcget_col_row_stats(ptrA, ptrRowStats, ptrColStats, ptrNnzrows, ct\u001b[39m.\u001b[39mc_float(threshold), rows, cols)\n\u001b[1;32m   1877\u001b[0m post_call(prev_device)\n\u001b[1;32m   1879\u001b[0m \u001b[39mif\u001b[39;00m threshold \u001b[39m>\u001b[39m \u001b[39m0.0\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/ctypes/__init__.py:387\u001b[0m, in \u001b[0;36mCDLL.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39mif\u001b[39;00m name\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m__\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m name\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    386\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(name)\n\u001b[0;32m--> 387\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(name)\n\u001b[1;32m    388\u001b[0m \u001b[39msetattr\u001b[39m(\u001b[39mself\u001b[39m, name, func)\n\u001b[1;32m    389\u001b[0m \u001b[39mreturn\u001b[39;00m func\n",
      "File \u001b[0;32m/usr/lib/python3.10/ctypes/__init__.py:392\u001b[0m, in \u001b[0;36mCDLL.__getitem__\u001b[0;34m(self, name_or_ordinal)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, name_or_ordinal):\n\u001b[0;32m--> 392\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_FuncPtr((name_or_ordinal, \u001b[39mself\u001b[39;49m))\n\u001b[1;32m    393\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(name_or_ordinal, \u001b[39mint\u001b[39m):\n\u001b[1;32m    394\u001b[0m         func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m=\u001b[39m name_or_ordinal\n",
      "\u001b[0;31mAttributeError\u001b[0m: /home/arjun/NewPytorchEnv/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cget_col_row_stats"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(model='gpt2', model_kwargs= {\"device_map\": \"auto\", \"load_in_8bit\": True}, max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 30 13:34:12 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| 53%   37C    P2   134W / 390W |   1346MiB / 24576MiB |      6%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1403      G   /usr/lib/xorg/Xorg                127MiB |\n",
      "|    0   N/A  N/A      1601      G   /usr/bin/gnome-shell               62MiB |\n",
      "|    0   N/A  N/A      3861      G   ...RendererForSitePerProcess       93MiB |\n",
      "|    0   N/A  N/A     29819      G   ...622961487944422528,262144      244MiB |\n",
      "|    0   N/A  N/A     37062      C   ...PytorchEnv/bin/python3.10      812MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NewPytorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
